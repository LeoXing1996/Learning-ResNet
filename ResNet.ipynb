{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoxing/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = slim.conv2d(input, \n",
    "#                      output_channels, \n",
    "#                      [kernel_height, kernel_width],\n",
    "#                      stride=1,\n",
    "#                      padding='SAME')\n",
    "\n",
    "# w = slim.model_variable(name, \n",
    "#                         shape=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_block_same(input_image, kernel_num, kernel_size, name):\n",
    "    '''\n",
    "    尺寸不变的残差链接\n",
    "    '''\n",
    "    with tf.name_scope(name):\n",
    "        # first layer\n",
    "        first_output = tf.nn.relu(slim.conv2d(input_image, kernel_num, kernel_size))\n",
    "        # second layer\n",
    "        second_output = slim.conv2d(first_output, kernel_num, kernel_size)\n",
    "        \n",
    "        output_image = tf.nn.relu(second_output + input_image)\n",
    "    return output_image\n",
    "\n",
    "def res_block_increase(input_image, kernel_num, kernel_size, name):\n",
    "    '''\n",
    "    尺寸改变的残差链接\n",
    "    '''\n",
    "    with tf.name_scope(name):\n",
    "        # first layer\n",
    "        first_output = tf.nn.relu(slim.conv2d(input_image, kernel_num, kernel_size, stride=2))\n",
    "        \n",
    "        # second layer\n",
    "        second_output = slim.conv2d(first_output, kernel_num, kernel_size)\n",
    "        \n",
    "        # reshape input\n",
    "        input_reshape = slim.conv2d(input_image, kernel_num, [1,1], stride=2, padding='VALID')\n",
    "        \n",
    "        output_image = tf.nn.relu(second_output + input_reshape)\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-1d97e31010cf>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/leoxing/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/leoxing/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MINST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/leoxing/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MINST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MINST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MINST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/leoxing/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MINST_data')\n",
    "\n",
    "# mnist shape:\n",
    "# pic : batch * 784\n",
    "# label: batch * 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-af97a18e952d>:42: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "image_shape = mnist.train.images.shape[1]\n",
    "width = np.sqrt(image_shape)\n",
    "height = np.sqrt(image_shape)\n",
    "channel = 1\n",
    "\n",
    "BATCH_SIZE = 50\n",
    "KERNEL_SIZE = [3, 3]\n",
    "\n",
    "LEARNING_RATE_BASE = 0.8\n",
    "LEARNING_RATE_DECAY = 0.99\n",
    "REGULARAZTION_RATE = 0.0001\n",
    "\n",
    "input_image = tf.placeholder(tf.float32, \n",
    "                             shape=[None, height, width, channel], \n",
    "                             name=\"Input_Image\")\n",
    "\n",
    "labels = tf.placeholder(tf.float32,\n",
    "                        shape=[None, 10],\n",
    "                        name=\"Labels\")\n",
    "\n",
    "output_temp_1 = res_block_same(input_image, 3, \n",
    "                               KERNEL_SIZE, \"output_temp_1\") # 28 * 28 * 1\n",
    "\n",
    "output_temp_2 = res_block_increase(output_temp_1, 6, \n",
    "                                   KERNEL_SIZE, \"output_temp_2\") # 14 * 14 * 6\n",
    "\n",
    "output_temp_3 = res_block_same(output_temp_2, 6,\n",
    "                              KERNEL_SIZE, \"output_temp_3\") # 14 * 14 * 6\n",
    "\n",
    "output_temp_4 = res_block_increase(output_temp_3, 12,\n",
    "                                  KERNEL_SIZE, \"output_temp_4\") # 7 * 7 * 12\n",
    "\n",
    "# AVG_POOL ---> 'SAME'  这里 ksize 似乎必须显式声明 batch size\n",
    "# 去掉池化之后效果变好了...\n",
    "# 似乎因为损失的数据变少了\n",
    "output_pool = tf.nn.avg_pool(output_temp_4, ksize=[BATCH_SIZE, 3, 3, 12], strides=[1,1,1,1], padding='SAME')\n",
    "output_pool = tf.reshape(output_temp_4, [-1, 7*7*12])\n",
    "\n",
    "\n",
    "# 1层FC\n",
    "w = slim.variable(\"Full_Connect_Weight\", shape=[7*7*12, 10])\n",
    "b = slim.variable(\"Full_Connect_Bias\", shape=[BATCH_SIZE, 10])\n",
    "output = tf.matmul(output_pool, w) + b\n",
    "\n",
    "# loss\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels, logits=output))\n",
    "labels_pre = tf.argmax(output)\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "learning_rate = tf.train.exponential_decay(LEARNING_RATE_BASE, global_step,\n",
    "                                           mnist.train.num_examples / BATCH_SIZE, LEARNING_RATE_DECAY)\n",
    "\n",
    "trainer = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "\n",
    "accu_rate = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(labels, axis=1), tf.argmax(output, axis=1)), tf.float32))\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step   50      Accuracy:  0.76   Loss: 0.49933\n",
      "Step  100      Accuracy:  0.94   Loss: 0.192217\n",
      "Step  150      Accuracy:  0.96   Loss: 0.230655\n",
      "Step  200      Accuracy:  0.92   Loss: 0.363342\n",
      "Step  250      Accuracy:  0.88   Loss: 0.467538\n",
      "Step  300      Accuracy:  0.82   Loss: 0.574525\n",
      "Step  350      Accuracy:  0.82   Loss: 0.543559\n",
      "Step  400      Accuracy:  0.82   Loss: 0.415361\n",
      "Step  450      Accuracy:   0.8   Loss: 0.617212\n",
      "Step  500      Accuracy:  0.92   Loss: 0.256725\n",
      "Step  550      Accuracy:   0.9   Loss: 0.331106\n",
      "Step  600      Accuracy:  0.86   Loss: 0.544242\n",
      "Step  650      Accuracy:   0.9   Loss: 0.362776\n",
      "Step  700      Accuracy:  0.92   Loss: 0.243449\n",
      "Step  750      Accuracy:  0.76   Loss: 0.573966\n",
      "Step  800      Accuracy:  0.88   Loss: 0.395885\n",
      "Step  850      Accuracy:  0.94   Loss: 0.303172\n",
      "Step  900      Accuracy:  0.86   Loss: 0.49256\n",
      "Step  950      Accuracy:  0.84   Loss: 0.335808\n"
     ]
    }
   ],
   "source": [
    "training_steps = 10000\n",
    "intervals = 100\n",
    "PATH = 'MODEL/mnistRes.ckpt'\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    loss_min = 100\n",
    "    for i in range(1, training_steps):\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        input_image_ = batch[0].reshape(BATCH_SIZE, 28, 28, 1)\n",
    "        labels_ = tf.one_hot(batch[1], depth=10).eval()\n",
    "        \n",
    "        usedData = {\n",
    "            input_image: input_image_,\n",
    "            labels: labels_ \n",
    "        }\n",
    "        \n",
    "        trainer.run(session=sess, feed_dict=usedData)\n",
    "        if i % intervals == 0:\n",
    "            accu_rate_ = accu_rate.eval(session=sess, feed_dict=usedData)\n",
    "            loss_ = loss.eval(session=sess, feed_dict=usedData)\n",
    "            print(\"Step %4d      Accuracy: %5g   Loss: %5g\" %(i, accu_rate_, loss_))\n",
    "            \n",
    "            if loss_ < loss:\n",
    "                saver.save(sess, PATH, global_step=i)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[2.  ]\n",
      "   [2.25]]\n",
      "\n",
      "  [[2.25]\n",
      "   [1.75]]]]\n",
      "[[[[2.  ]\n",
      "   [2.25]\n",
      "   [2.  ]]\n",
      "\n",
      "  [[2.25]\n",
      "   [1.75]\n",
      "   [1.5 ]]\n",
      "\n",
      "  [[2.  ]\n",
      "   [1.5 ]\n",
      "   [2.  ]]]]\n",
      "[[[[2.   2.  ]\n",
      "   [2.25 2.25]]\n",
      "\n",
      "  [[2.25 2.25]\n",
      "   [1.75 1.75]]]]\n",
      "[[[[1. 1.]\n",
      "   [2. 2.]\n",
      "   [3. 3.]]\n",
      "\n",
      "  [[2. 2.]\n",
      "   [3. 3.]\n",
      "   [1. 1.]]\n",
      "\n",
      "  [[3. 3.]\n",
      "   [1. 1.]\n",
      "   [2. 2.]]]]\n"
     ]
    }
   ],
   "source": [
    "# Pooling\n",
    "# tf.nn.avg_pool(value, ksize, strides, padding)\n",
    "# value 为输入 形如 [batch height width channels] 的 4-D tensor 直接写一个二维数组然后 reshape 就行\n",
    "# ksize 为池化尺寸 形如 [batch height width channels] 的 1-D tensor\n",
    "# strides 池化步长 形式与 ksize 相同\n",
    "# padding 有 SAME 和 VALID 两个选项\n",
    "\n",
    "\n",
    "t = np.array([[1,2,3],[2,3,1],[3,1,2]])\n",
    "t.shape\n",
    "\n",
    "t_ = tf.constant(t.reshape([1,3,3,1]), dtype=tf.float32)\n",
    "res = tf.nn.avg_pool(t_, ksize=[1,2,2,1], strides=[1,1,1,1], padding='VALID')\n",
    "res_ = tf.nn.avg_pool(t_, ksize=[1,2,2,1], strides=[1,1,1,1], padding='SAME')\n",
    "with tf.Session() as sess:\n",
    "    print(res.eval())\n",
    "    print(res_.eval())\n",
    "    \n",
    "\n",
    "# 多 Channel 的情况 \n",
    "\n",
    "t1 = np.array([[1,2,3],[2,3,1],[3,1,2]])\n",
    "t2 = np.array([[1,2,3],[2,3,1],[3,1,2]])\n",
    "\n",
    "tt = np.array([     # tt 为 2 channels\n",
    "    [t1[i][j], t2[i][j]] for i in range(3) for j in range(3)\n",
    "]).reshape([1,3,3,2])\n",
    "\n",
    "tt = tf.constant(tt, dtype=tf.float32)\n",
    "\n",
    "Res = tf.nn.avg_pool(tt, ksize=[1,2,2,1], strides=[1,1,1,1], padding='VALID')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(Res.eval())\n",
    "    print(tt.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
